{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c754072-8abf-4155-bb05-b5c5ebd54775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9ee3491-750b-4112-ac4c-4e1f42a84eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32cb60b4-8f4e-4a9f-8584-18150f2d0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dict, transform=None, max_images=100):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dict = labels_dict\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get all image names from labels_dict keys\n",
    "        self.img_names = list(labels_dict.keys())\n",
    "        \n",
    "        # Keep only first max_images (default 100)\n",
    "        self.img_names = self.img_names[:max_images]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_names[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels_dict[img_name]\n",
    "        return image, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e169ad34-1620-48b2-b67f-731bb8fb50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mixture of Experts Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8f60d3a-0ad9-4890-b76e-b48888648456",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpertCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExpertCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.fc = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79d0adca-f322-40d9-9d3f-1759f2e1ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatingNetwork(nn.Module):\n",
    "    def __init__(self, num_experts):\n",
    "        super(GatingNetwork, self).__init__()\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.fc = nn.Linear(16, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gate(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.softmax(self.fc(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6393afa-b5ee-4a60-ad46-e370432bb8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureOfExperts(nn.Module):\n",
    "    def __init__(self, num_experts):\n",
    "        super(MixtureOfExperts, self).__init__()\n",
    "        self.experts = nn.ModuleList([ExpertCNN() for _ in range(num_experts)])\n",
    "        self.gating = GatingNetwork(num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate_weights = self.gating(x)  # shape: [batch_size, num_experts]\n",
    "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=2)  # shape: [batch, classes, experts]\n",
    "        out = torch.bmm(expert_outputs, gate_weights.unsqueeze(2)).squeeze(2)  # shape: [batch, classes]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11fe2a0a-0a24-49a8-af1f-c1952a55ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating Label Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575c42c-140f-49b5-b297-a0a7c70127fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels_dict(dataset_path):\n",
    "    labels_dict = {}\n",
    "    for label_type in ['real', 'fake']:\n",
    "        label = 0 if label_type == 'real' else 1\n",
    "        folder_path = os.path.join(dataset_path, label_type)\n",
    "        for fname in os.listdir(folder_path):\n",
    "            if fname.endswith(\".jpg\") or fname.endswith(\".png\"):\n",
    "                labels_dict[os.path.join(label_type, fname)] = label\n",
    "    return labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9f02af9-2ae4-4cfe-908e-034467f89dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df8d7037-5859-4c59-acfd-5d9075914ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(img_dir, num_epochs=5, batch_size=8, num_experts=3):\n",
    "    labels_dict = create_labels_dict(img_dir)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((1024, 1024)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    dataset = FaceDataset(img_dir, labels_dict, transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = MixtureOfExperts(num_experts=num_experts)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd6dde49-bddf-4c38-8d26-59c8dfcf6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc70aee1-ed18-42c2-9421-973c7090543c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.6576\n",
      "Epoch 2/5, Loss: 0.6365\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    img_dir = r\"C:\\Users\\aasth\\Downloads\\dataset2\\Final Dataset\"\n",
    "    train_model(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4422255e-0210-4266-9bef-712e1ed7d5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c497262-cbc0-4e34-a72d-1593494c545d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
